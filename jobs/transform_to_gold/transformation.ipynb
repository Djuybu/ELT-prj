{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88af04bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dae09d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01ecca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = SparkContext.getOrCreate()\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Finding strategies for dataframe transformation\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e864bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = spark.read.csv(\"/app/airflow/ELT-prj/files/product_cleaned.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf78d963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "client_df = spark.read.csv(\"/app/airflow/ELT-prj/files/clients.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2a323d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases_df = spark.read.csv(\"/app/airflow/ELT-prj/files/purchases_demo.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72379b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df = spark.read.csv(\"/app/airflow/ELT-prj/files/store.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65b5e6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- level_1: string (nullable = true)\n",
      " |-- level_2: string (nullable = true)\n",
      " |-- level_3: string (nullable = true)\n",
      " |-- level_4: string (nullable = true)\n",
      " |-- brand_name: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- product_price: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- first_issue_date: timestamp (nullable = true)\n",
      " |-- first_redeem_date: timestamp (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- client_id: double (nullable = true)\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- transaction_datetime: date (nullable = true)\n",
      " |-- regular_points_received: timestamp (nullable = true)\n",
      " |-- express_points_received: integer (nullable = true)\n",
      " |-- regular_points_spent: integer (nullable = true)\n",
      " |-- express_points_spent: integer (nullable = true)\n",
      " |-- purchase_sum: integer (nullable = true)\n",
      " |-- store_id: integer (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_quantity: string (nullable = true)\n",
      " |-- trn_sum_from_iss: integer (nullable = true)\n",
      " |-- trn_sum_from_red: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- store_id: string (nullable = true)\n",
      " |-- store_name: string (nullable = true)\n",
      " |-- store_location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_df.printSchema()\n",
    "client_df.printSchema()\n",
    "purchases_df.printSchema()\n",
    "store_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f45939b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      store_location|\n",
      "+--------------------+\n",
      "|    Ward 1, Vung Tau|\n",
      "|   Gia Rai, Bac Lieu|\n",
      "|Quang Ninh, Quang...|\n",
      "|   Quy Chau, Nghe An|\n",
      "|District 3, Ho Ch...|\n",
      "| Vinh Hoa, Nha Trang|\n",
      "|Bac Lieu City, Ba...|\n",
      "|    Tu Son, Bac Ninh|\n",
      "|    Ward 3, Vung Tau|\n",
      "|  Hoang Mai, Nghe An|\n",
      "|  Thanh Liem, Ha Nam|\n",
      "|  Dong Ha, Quang Tri|\n",
      "|     Dam Doi, Ca Mau|\n",
      "|Phuoc Long, Bac Lieu|\n",
      "|Duong Kinh, Hai P...|\n",
      "|  Tran De, Soc Trang|\n",
      "| Gia Vien, Ninh Binh|\n",
      "|Soc Trang City, S...|\n",
      "|Song Cong, Thai N...|\n",
      "| Vinh Hai, Nha Trang|\n",
      "| Ha Tien, Kien Giang|\n",
      "|Thanh Hoa City, T...|\n",
      "| Vinh Yen, Vinh Phuc|\n",
      "|      O Mon, Can Tho|\n",
      "|Nam Dinh City, Na...|\n",
      "|District 4, Ho Ch...|\n",
      "|Ngu Hanh Son, Da ...|\n",
      "| Giao Thuy, Nam Dinh|\n",
      "|  Tan Yen, Bac Giang|\n",
      "|  Kim Son, Ninh Binh|\n",
      "|  Tan Chau, An Giang|\n",
      "|Ha Tinh City, Ha ...|\n",
      "|    Duy Tien, Ha Nam|\n",
      "|    My Loc, Nam Dinh|\n",
      "|Lang Giang, Bac G...|\n",
      "|Dong Trieu, Quang...|\n",
      "|    Son Tra, Da Nang|\n",
      "| Ca Mau City, Ca Mau|\n",
      "|District 2, Ho Ch...|\n",
      "| Thang Tam, Vung Tau|\n",
      "|   Thot Not, Can Tho|\n",
      "|  Hoa Binh, Bac Lieu|\n",
      "| Cao Lanh, Dong Thap|\n",
      "| Gio Linh, Quang Tri|\n",
      "|       Vinh, Nghe An|\n",
      "|Thuan Thanh, Bac ...|\n",
      "|   Di An, Binh Duong|\n",
      "|Rach Gia, Kien Giang|\n",
      "|    Kim Bang, Ha Nam|\n",
      "|Thuan An, Binh Duong|\n",
      "|Duc Linh, Binh Thuan|\n",
      "|  Kien An, Hai Phong|\n",
      "|    Binh Luc, Ha Nam|\n",
      "|Thai Nguyen City,...|\n",
      "|Tan Uyen, Binh Duong|\n",
      "|    Go Dau, Tay Ninh|\n",
      "|     Cua Lo, Nghe An|\n",
      "|     Nam Can, Ca Mau|\n",
      "| An Bien, Kien Giang|\n",
      "|Huong Tra, Thua T...|\n",
      "|      U Minh, Ca Mau|\n",
      "|   Sa Dec, Dong Thap|\n",
      "| Lien Chieu, Da Nang|\n",
      "|  Bim Son, Thanh Hoa|\n",
      "|Ngo Quyen, Hai Phong|\n",
      "|Mong Cai, Quang Ninh|\n",
      "| Thoai Son, An Giang|\n",
      "|    Quy Hop, Nghe An|\n",
      "|Tay Ninh City, Ta...|\n",
      "| Hoa Thanh, Tay Ninh|\n",
      "|District 1, Ho Ch...|\n",
      "|Hong Bang, Hai Phong|\n",
      "|  Le Chan, Hai Phong|\n",
      "|Bo Trach, Quang Binh|\n",
      "|Trang Bang, Tay Ninh|\n",
      "|Thanh Binh, Dong ...|\n",
      "|Phu Luong, Thai N...|\n",
      "|      Phu Ly, Ha Nam|\n",
      "|Quang Tri Town, Q...|\n",
      "|    Que Vo, Bac Ninh|\n",
      "|Long Xuyen, An Giang|\n",
      "|   Thoi Binh, Ca Mau|\n",
      "|Vinh Linh, Quang Tri|\n",
      "|  Dong Hai, Bac Lieu|\n",
      "| My Xuyen, Soc Trang|\n",
      "| Lai Vung, Dong Thap|\n",
      "|Phan Thiet, Binh ...|\n",
      "|  Chau Doc, An Giang|\n",
      "|Lap Thach, Vinh Phuc|\n",
      "|    Hoan Kiem, Hanoi|\n",
      "|Thu Dau Mot, Binh...|\n",
      "|    Ward 2, Vung Tau|\n",
      "| Yen Dung, Bac Giang|\n",
      "|    Hoang Mai, Hanoi|\n",
      "| Hong Ngu, Dong Thap|\n",
      "| Phong Dien, Can Tho|\n",
      "| Hon Dat, Kien Giang|\n",
      "|      Ba Dinh, Hanoi|\n",
      "|Dong Hoi, Quang Binh|\n",
      "|  Loc Tho, Nha Trang|\n",
      "|  Ninh Kieu, Can Tho|\n",
      "|   Hai Chau, Da Nang|\n",
      "| Hai Ba Trung, Hanoi|\n",
      "|   Tri Ton, An Giang|\n",
      "|  Sam Son, Thanh Hoa|\n",
      "|Phuoc Hai, Nha Trang|\n",
      "|  Thanh Khe, Da Nang|\n",
      "|Phong Dien, Thua ...|\n",
      "|    Ward 4, Vung Tau|\n",
      "|Ham Thuan Bac, Bi...|\n",
      "|   Tien Du, Bac Ninh|\n",
      "|     Ky Anh, Ha Tinh|\n",
      "|   Hoa Lu, Ninh Binh|\n",
      "|   Ben Cau, Tay Ninh|\n",
      "|Phu Vang, Thua Th...|\n",
      "| Hai Lang, Quang Tri|\n",
      "|   La Gi, Binh Thuan|\n",
      "|Tuy Phong, Binh T...|\n",
      "|Bac Ninh City, Ba...|\n",
      "| Hiep Hoa, Bac Giang|\n",
      "|  Nga Nam, Soc Trang|\n",
      "|Nong Cong, Thanh Hoa|\n",
      "|Bac Giang City, B...|\n",
      "| Tam Diep, Ninh Binh|\n",
      "| Cam Pha, Quang Ninh|\n",
      "|  Hong Linh, Ha Tinh|\n",
      "|  Cam Xuyen, Ha Tinh|\n",
      "|  Binh Thuy, Can Tho|\n",
      "| Ben Cat, Binh Duong|\n",
      "| Dai Tu, Thai Nguyen|\n",
      "|Huong Thuy, Thua ...|\n",
      "| Phuc Yen, Vinh Phuc|\n",
      "|   Hai Hau, Nam Dinh|\n",
      "|Pho Yen, Thai Nguyen|\n",
      "|      Dong Da, Hanoi|\n",
      "|  Ba Don, Quang Binh|\n",
      "| Le Thuy, Quang Binh|\n",
      "|Tam Duong, Vinh Phuc|\n",
      "|Phu Quoc, Kien Giang|\n",
      "|   Thach Ha, Ha Tinh|\n",
      "| Ha Long, Quang Ninh|\n",
      "|District 5, Ho Ch...|\n",
      "| Tho Xuan, Thanh Hoa|\n",
      "|Ninh Binh City, N...|\n",
      "|  Yen Lac, Vinh Phuc|\n",
      "|Vinh Chau, Soc Trang|\n",
      "|     Y Yen, Nam Dinh|\n",
      "| Hue, Thua Thien Hue|\n",
      "|Vinh Nguyen, Nha ...|\n",
      "| Uong Bi, Quang Ninh|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "store_df.select(\"store_location\").distinct().show(150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b394bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_map = {\n",
    "    \"northwest\": [\"Lai Chau\", \"Dien Bien\", \"Son La\", \"Hoa Binh\", \"Lao Cai\", \"Yen Bai\"],\n",
    "    \"northeast\": [\"Ha Giang\", \"Cao Bang\", \"Bac Kan\", \"Tuyen Quang\", \"Lang Son\", \"Thai Nguyen\",\n",
    "                  \"Phu Tho\", \"Bac Giang\", \"Quang Ninh\"],\n",
    "    \"red_river_delta\": [\"Hanoi\", \"Bac Ninh\", \"Ha Nam\", \"Hung Yen\", \"Hai Duong\", \"Hai Phong\",\n",
    "                        \"Nam Dinh\", \"Ninh Binh\", \"Thai Binh\", \"Vinh Phuc\"],\n",
    "    \"north_central\": [\"Thanh Hoa\", \"Nghe An\", \"Ha Tinh\", \"Quang Binh\", \"Quang Tri\", \"Thua Thien Hue\"],\n",
    "    \"south_central\": [\"Da Nang\", \"Quang Nam\", \"Quang Ngai\", \"Binh Dinh\", \"Phu Yen\", \"Khanh Hoa\",\n",
    "                      \"Ninh Thuan\", \"Binh Thuan\"],\n",
    "    \"central_highlands\": [\"Kon Tum\", \"Gia Lai\", \"Dak Lak\", \"Dak Nong\", \"Lam Dong\"],\n",
    "    \"southeast\": [\"TP Ho Chi Minh\", \"Binh Duong\", \"Dong Nai\", \"Tay Ninh\", \"Ba Ria Vung Tau\", \"Binh Phuoc\"],\n",
    "    \"southwest\": [\"Long An\", \"Tien Giang\", \"Ben Tre\", \"Tra Vinh\", \"Vinh Long\", \"Dong Thap\",\n",
    "                  \"An Giang\", \"Can Tho\", \"Hau Giang\", \"Kien Giang\", \"Soc Trang\", \"Bac Lieu\", \"Ca Mau\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82d7d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /app/airflow/ELT-prj/.venv/lib/python3.12/site-packages (1.3.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca29e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22a73b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_from_location(location):\n",
    "    if location is None:\n",
    "        return None\n",
    "    try:\n",
    "        # Lấy tỉnh/thành từ phần sau dấu phẩy\n",
    "        province_raw = location.split(\",\")[-1].strip()\n",
    "        # Chuyển về không dấu, viết hoa chữ cái đầu mỗi từ\n",
    "        province = ' '.join(word.capitalize() for word in unidecode(province_raw).split())\n",
    "        \n",
    "        for region, provinces in region_map.items():\n",
    "            if province in provinces:\n",
    "                return region\n",
    "        return \"unknown\"\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "get_region_udf = udf(get_region_from_location, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72787858",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df = store_df.withColumn(\"region\", get_region_udf(store_df[\"store_location\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0835076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+--------------------+---------------+\n",
      "|  store_id|       store_name|      store_location|         region|\n",
      "+----------+-----------------+--------------------+---------------+\n",
      "|291cedf475|    Binh Duong 26| Ben Cat, Binh Duong|      southeast|\n",
      "|1aae841dbb|       Da Nang 06|Ngu Hanh Son, Da ...|  south_central|\n",
      "|e10533694b|      Bac Lieu 69|Phuoc Long, Bac Lieu|      southwest|\n",
      "|6ce43e3ee3|       Can Tho 68| Phong Dien, Can Tho|      southwest|\n",
      "|d57f269b64|         Hanoi 67| Hai Ba Trung, Hanoi|red_river_delta|\n",
      "|ae3fd8139a|     Vinh Phuc 91|Lap Thach, Vinh Phuc|red_river_delta|\n",
      "|9522388621|      Nam Dinh 81|     Y Yen, Nam Dinh|red_river_delta|\n",
      "|4a27070917|      Bac Lieu 17|   Gia Rai, Bac Lieu|      southwest|\n",
      "|7c6c4bcc5b|      Nam Dinh 21|   Hai Hau, Nam Dinh|red_river_delta|\n",
      "|ca0c3907f1|     Bac Giang 28|Bac Giang City, B...|      northeast|\n",
      "|d0a0d857c5|     Quang Tri 35|  Dong Ha, Quang Tri|  north_central|\n",
      "|88712df1a5|        Ca Mau 45|     Nam Can, Ca Mau|      southwest|\n",
      "|17e6026f97|    Binh Duong 45|Thuan An, Binh Duong|      southeast|\n",
      "|484c7a0432|      Bac Ninh 95|   Tien Du, Bac Ninh|red_river_delta|\n",
      "|8fd33546ac|     Vinh Phuc 87|  Yen Lac, Vinh Phuc|red_river_delta|\n",
      "|d659a948d2|      Bac Lieu 90|  Dong Hai, Bac Lieu|      southwest|\n",
      "|9df7cbdb0d|      An Giang 15|  Tan Chau, An Giang|      southwest|\n",
      "|d01c52c10b|    Quang Binh 57| Le Thuy, Quang Binh|  north_central|\n",
      "|0c608a8aca|      Nam Dinh 32| Giao Thuy, Nam Dinh|red_river_delta|\n",
      "|18599a5c9f|    Quang Binh 39|Dong Hoi, Quang Binh|  north_central|\n",
      "|3c516c07a6|   Ho Chi Minh 62|District 2, Ho Ch...|        unknown|\n",
      "|4ee2b95f3d|     Vinh Phuc 57|Lap Thach, Vinh Phuc|red_river_delta|\n",
      "|f63e5c3fef|     Bac Giang 33|  Tan Yen, Bac Giang|      northeast|\n",
      "|5784fe73da|    Quang Ninh 18| Cam Pha, Quang Ninh|      northeast|\n",
      "|0f32a9fe59|Thua Thien Hue 34|Huong Thuy, Thua ...|  north_central|\n",
      "+----------+-----------------+--------------------+---------------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "store_df.show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d19cc273",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_store_format = [\"Flagship store\", \"Department store\", \"Supermarket\", \"Convenience store\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11f9b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d279c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_random_store_format():\n",
    "    return random.choice(random_store_format)\n",
    "\n",
    "assign_store_format_udf = udf(assign_random_store_format, StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e7822b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df = store_df.withColumn(\"store_format\", assign_store_format_udf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1443e943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+--------------------+---------------+-----------------+\n",
      "|  store_id|       store_name|      store_location|         region|     store_format|\n",
      "+----------+-----------------+--------------------+---------------+-----------------+\n",
      "|291cedf475|    Binh Duong 26| Ben Cat, Binh Duong|      southeast| Department store|\n",
      "|1aae841dbb|       Da Nang 06|Ngu Hanh Son, Da ...|  south_central|Convenience store|\n",
      "|e10533694b|      Bac Lieu 69|Phuoc Long, Bac Lieu|      southwest|Convenience store|\n",
      "|6ce43e3ee3|       Can Tho 68| Phong Dien, Can Tho|      southwest|      Supermarket|\n",
      "|d57f269b64|         Hanoi 67| Hai Ba Trung, Hanoi|red_river_delta| Department store|\n",
      "|ae3fd8139a|     Vinh Phuc 91|Lap Thach, Vinh Phuc|red_river_delta|Convenience store|\n",
      "|9522388621|      Nam Dinh 81|     Y Yen, Nam Dinh|red_river_delta|      Supermarket|\n",
      "|4a27070917|      Bac Lieu 17|   Gia Rai, Bac Lieu|      southwest|Convenience store|\n",
      "|7c6c4bcc5b|      Nam Dinh 21|   Hai Hau, Nam Dinh|red_river_delta| Department store|\n",
      "|ca0c3907f1|     Bac Giang 28|Bac Giang City, B...|      northeast|      Supermarket|\n",
      "|d0a0d857c5|     Quang Tri 35|  Dong Ha, Quang Tri|  north_central|   Flagship store|\n",
      "|88712df1a5|        Ca Mau 45|     Nam Can, Ca Mau|      southwest|      Supermarket|\n",
      "|17e6026f97|    Binh Duong 45|Thuan An, Binh Duong|      southeast|      Supermarket|\n",
      "|484c7a0432|      Bac Ninh 95|   Tien Du, Bac Ninh|red_river_delta| Department store|\n",
      "|8fd33546ac|     Vinh Phuc 87|  Yen Lac, Vinh Phuc|red_river_delta| Department store|\n",
      "|d659a948d2|      Bac Lieu 90|  Dong Hai, Bac Lieu|      southwest| Department store|\n",
      "|9df7cbdb0d|      An Giang 15|  Tan Chau, An Giang|      southwest|      Supermarket|\n",
      "|d01c52c10b|    Quang Binh 57| Le Thuy, Quang Binh|  north_central|Convenience store|\n",
      "|0c608a8aca|      Nam Dinh 32| Giao Thuy, Nam Dinh|red_river_delta|      Supermarket|\n",
      "|18599a5c9f|    Quang Binh 39|Dong Hoi, Quang Binh|  north_central|      Supermarket|\n",
      "|3c516c07a6|   Ho Chi Minh 62|District 2, Ho Ch...|        unknown|   Flagship store|\n",
      "|4ee2b95f3d|     Vinh Phuc 57|Lap Thach, Vinh Phuc|red_river_delta|   Flagship store|\n",
      "|f63e5c3fef|     Bac Giang 33|  Tan Yen, Bac Giang|      northeast|Convenience store|\n",
      "|5784fe73da|    Quang Ninh 18| Cam Pha, Quang Ninh|      northeast| Department store|\n",
      "|0f32a9fe59|Thua Thien Hue 34|Huong Thuy, Thua ...|  north_central|Convenience store|\n",
      "+----------+-----------------+--------------------+---------------+-----------------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "store_df.show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0fa616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e56be21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df.write.csv(\"/app/airflow/ELT-prj/files/store_updated.csv\", header=True, mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b0ef448",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_lake_df = store_df.select(\"store_id\", \"store_name\", \"store_location\", \"region\", \"store_format\")\n",
    "product_lake_df = product_df\n",
    "client_lake_df = client_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcc10f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr, sequence, to_date, year, month, dayofmonth, dayofweek, weekofyear, dayofyear, quarter, date_format\n",
    "from pyspark.sql.types import DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6396b0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----------+------------------+------------+-----------+------------+-----+----------+-------+----+----------+----------+\n",
      "| full_date|date_key|day_of_week|day_number_of_week|day_of_month|day_of_year|week_of_year|month|month_name|quarter|year|is_weekend|is_holiday|\n",
      "+----------+--------+-----------+------------------+------------+-----------+------------+-----+----------+-------+----+----------+----------+\n",
      "|2018-11-22|20181122|   Thursday|                 5|          22|        326|          47|   11|  November|      4|2018|         0|         0|\n",
      "|2018-11-23|20181123|     Friday|                 6|          23|        327|          47|   11|  November|      4|2018|         0|         0|\n",
      "|2018-11-24|20181124|   Saturday|                 7|          24|        328|          47|   11|  November|      4|2018|         1|         0|\n",
      "|2018-11-25|20181125|     Sunday|                 1|          25|        329|          47|   11|  November|      4|2018|         1|         0|\n",
      "|2018-11-26|20181126|     Monday|                 2|          26|        330|          48|   11|  November|      4|2018|         0|         0|\n",
      "+----------+--------+-----------+------------------+------------+-----------+------------+-----+----------+-------+----+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Khoảng thời gian muốn tạo\n",
    "start_date = \"2018-11-22\"\n",
    "end_date = \"2019-03-19\"\n",
    "\n",
    "# Tạo dãy ngày liên tiếp\n",
    "df_date = spark.sql(f\"SELECT sequence(to_date('{start_date}'), to_date('{end_date}'), interval 1 day) as date_seq\") \\\n",
    "    .selectExpr(\"explode(date_seq) as full_date\")\n",
    "\n",
    "# Tạo các cột dim_time\n",
    "dim_time = df_date.withColumn(\"date_key\", expr(\"CAST(date_format(full_date, 'yyyyMMdd') AS INT)\")) \\\n",
    "    .withColumn(\"day_of_week\", date_format(col(\"full_date\"), \"EEEE\")) \\\n",
    "    .withColumn(\"day_number_of_week\", dayofweek(\"full_date\")) \\\n",
    "    .withColumn(\"day_of_month\", dayofmonth(\"full_date\")) \\\n",
    "    .withColumn(\"day_of_year\", dayofyear(\"full_date\")) \\\n",
    "    .withColumn(\"week_of_year\", weekofyear(\"full_date\")) \\\n",
    "    .withColumn(\"month\", month(\"full_date\")) \\\n",
    "    .withColumn(\"month_name\", date_format(\"full_date\", \"MMMM\")) \\\n",
    "    .withColumn(\"quarter\", quarter(\"full_date\")) \\\n",
    "    .withColumn(\"year\", year(\"full_date\")) \\\n",
    "    .withColumn(\"is_weekend\", expr(\"CASE WHEN dayofweek(full_date) IN (1, 7) THEN 1 ELSE 0 END\")) \\\n",
    "    .withColumn(\"is_holiday\", expr(\"0\"))  # Bạn có thể cập nhật logic holiday riêng nếu có\n",
    "\n",
    "# Xem thử\n",
    "dim_time.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ebc1d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `unit_price` cannot be resolved. Did you mean one of the following? [`client_id`, `store_id`, `product_id`, `purchase_sum`, `transaction_id`].;\n'Project [client_id#281, transaction_id#282, transaction_datetime#283, regular_points_received#284, express_points_received#285, regular_points_spent#286, express_points_spent#287, (('unit_price * product_quantity#291) - 'discount_amount) AS purchase_sum#581, store_id#289, product_id#290, product_quantity#291, trn_sum_from_iss#292, trn_sum_from_red#293]\n+- Relation [client_id#281,transaction_id#282,transaction_datetime#283,regular_points_received#284,express_points_received#285,regular_points_spent#286,express_points_spent#287,purchase_sum#288,store_id#289,product_id#290,product_quantity#291,trn_sum_from_iss#292,trn_sum_from_red#293] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m col, to_date, expr\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Tạo purchase_sum (tổng tiền sau giảm giá)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_sales = \u001b[43mpurchases_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpurchase_sum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43munit_price\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproduct_quantity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdiscount_amount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Chuẩn hóa thời gian và nối với dim_time để lấy date_key\u001b[39;00m\n\u001b[32m     10\u001b[39m df_sales = df_sales.withColumn(\u001b[33m\"\u001b[39m\u001b[33mtransaction_date\u001b[39m\u001b[33m\"\u001b[39m, to_date(\u001b[33m\"\u001b[39m\u001b[33mtransaction_datetime\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/sql/dataframe.py:5176\u001b[39m, in \u001b[36mDataFrame.withColumn\u001b[39m\u001b[34m(self, colName, col)\u001b[39m\n\u001b[32m   5171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[32m   5172\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[32m   5173\u001b[39m         error_class=\u001b[33m\"\u001b[39m\u001b[33mNOT_COLUMN\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5174\u001b[39m         message_parameters={\u001b[33m\"\u001b[39m\u001b[33marg_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcol\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33marg_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col).\u001b[34m__name__\u001b[39m},\n\u001b[32m   5175\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m5176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.sparkSession)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    181\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mAnalysisException\u001b[39m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `unit_price` cannot be resolved. Did you mean one of the following? [`client_id`, `store_id`, `product_id`, `purchase_sum`, `transaction_id`].;\n'Project [client_id#281, transaction_id#282, transaction_datetime#283, regular_points_received#284, express_points_received#285, regular_points_spent#286, express_points_spent#287, (('unit_price * product_quantity#291) - 'discount_amount) AS purchase_sum#581, store_id#289, product_id#290, product_quantity#291, trn_sum_from_iss#292, trn_sum_from_red#293]\n+- Relation [client_id#281,transaction_id#282,transaction_datetime#283,regular_points_received#284,express_points_received#285,regular_points_spent#286,express_points_spent#287,purchase_sum#288,store_id#289,product_id#290,product_quantity#291,trn_sum_from_iss#292,trn_sum_from_red#293] csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ed706df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- store_id: string (nullable = true)\n",
      " |-- date_key: integer (nullable = true)\n",
      " |-- transaction_datetime: date (nullable = true)\n",
      " |-- product_quantity: integer (nullable = true)\n",
      " |-- unit_price: double (nullable = true)\n",
      " |-- discount_amount: double (nullable = true)\n",
      " |-- purchase_sum: double (nullable = true)\n",
      " |-- regular_points_received: timestamp (nullable = true)\n",
      " |-- payment_method: string (nullable = false)\n",
      "\n",
      "+--------------+----------+---------+--------+--------+--------------------+----------------+----------+---------------+------------+-----------------------+--------------+\n",
      "|transaction_id|product_id|client_id|store_id|date_key|transaction_datetime|product_quantity|unit_price|discount_amount|purchase_sum|regular_points_received|payment_method|\n",
      "+--------------+----------+---------+--------+--------+--------------------+----------------+----------+---------------+------------+-----------------------+--------------+\n",
      "|    7e3e2e3984|54a4a11a29|  12768.0|    1007|20181201|          2018-12-01|            NULL|      NULL|           NULL|        NULL|    2025-04-17 07:12:45|           POS|\n",
      "|    7e3e2e3984|54a4a11a29|  12768.0|    1007|20181201|          2018-12-01|            NULL|      NULL|           NULL|        NULL|    2025-04-17 07:12:45|           POS|\n",
      "|    7e3e2e3984|54a4a11a29|  12768.0|    1007|20181201|          2018-12-01|            NULL|      NULL|           NULL|        NULL|    2025-04-17 07:12:45|           POS|\n",
      "|    7e3e2e3984|54a4a11a29|  12768.0|    1007|20181201|          2018-12-01|            NULL|      NULL|           NULL|        NULL|    2025-04-17 07:12:45|           POS|\n",
      "|    7e3e2e3984|54a4a11a29|  12768.0|    1007|20181201|          2018-12-01|            NULL|      NULL|           NULL|        NULL|    2025-04-17 07:12:45|           POS|\n",
      "|    7e3e2e3984|54a4a11a29|  12768.0|    1007|20181201|          2018-12-01|            NULL|      NULL|           NULL|        NULL|    2025-04-17 07:12:45|           POS|\n",
      "|    7e3e2e3984|54a4a11a29|  12768.0|    1007|20181201|          2018-12-01|            NULL|      NULL|           NULL|        NULL|    2025-04-17 07:12:45|           POS|\n",
      "|    7e3e2e3984|54a4a11a29|  12768.0|    1007|20181201|          2018-12-01|            NULL|      NULL|           NULL|        NULL|    2025-04-17 07:12:45|           POS|\n",
      "|    7e3e2e3984|54a4a11a29|  12768.0|    1007|20181201|          2018-12-01|            NULL|      NULL|           NULL|        NULL|    2025-04-17 07:12:45|           POS|\n",
      "|    7e3e2e3984|54a4a11a29|  12768.0|    1007|20181201|          2018-12-01|            NULL|      NULL|           NULL|        NULL|    2025-04-17 07:12:45|           POS|\n",
      "+--------------+----------+---------+--------+--------+--------------------+----------------+----------+---------------+------------+-----------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions = purchases_df \\\n",
    "    .withColumn(\"client_id\", col(\"client_id\").cast(\"string\")) \\\n",
    "    .withColumn(\"store_id\", col(\"store_id\").cast(\"string\")) \\\n",
    "    .withColumn(\"product_quantity\", col(\"product_quantity\").cast(\"int\")) \\\n",
    "    .withColumn(\"transaction_datetime\", to_date(\"transaction_datetime\")) \\\n",
    "    .withColumn(\"date_key\", expr(\"CAST(date_format(transaction_datetime, 'yyyyMMdd') AS INT)\"))\n",
    "\n",
    "# Chuẩn hóa bảng sản phẩm để có unit_price\n",
    "products = product_df.withColumnRenamed(\"product_price\", \"unit_price\")\n",
    "\n",
    "# Join với products để lấy đơn giá\n",
    "fact_sales = transactions.join(products.select(\"product_id\", \"unit_price\"), on=\"product_id\", how=\"left\")\n",
    "\n",
    "# Tính discount_amount = 5% đơn giá * số lượng\n",
    "fact_sales = fact_sales.withColumn(\"discount_amount\", expr(\"unit_price * product_quantity * 0.05\"))\n",
    "\n",
    "# Tính lại purchase_sum nếu chưa chuẩn\n",
    "fact_sales = fact_sales.withColumn(\"purchase_sum\", expr(\"unit_price * product_quantity - discount_amount\"))\n",
    "\n",
    "# Gán cố định payment_method nếu không có\n",
    "fact_sales = fact_sales.withColumn(\"payment_method\", expr(\"'POS'\"))\n",
    "\n",
    "# Chọn đúng thứ tự các trường theo mô hình fact_sales\n",
    "fact_sales_final = fact_sales.select(\n",
    "    \"transaction_id\",\n",
    "    \"product_id\",\n",
    "    \"client_id\",\n",
    "    \"store_id\",\n",
    "    \"date_key\",\n",
    "    \"transaction_datetime\",\n",
    "    \"product_quantity\",\n",
    "    \"unit_price\",\n",
    "    \"discount_amount\",\n",
    "    \"purchase_sum\",\n",
    "    \"regular_points_received\",\n",
    "    \"payment_method\"\n",
    ")\n",
    "\n",
    "# Ghi xuống định dạng Delta Lake\n",
    "fact_sales_final.printSchema()\n",
    "fact_sales_final.show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cdad22",
   "metadata": {},
   "source": [
    "root\n",
    " |-- product_id: string (nullable = true)\n",
    " |-- level_1: string (nullable = true)\n",
    " |-- level_2: string (nullable = true)\n",
    " |-- level_3: string (nullable = true)\n",
    " |-- level_4: string (nullable = true)\n",
    " |-- brand_name: string (nullable = true)\n",
    " |-- product_name: string (nullable = true)\n",
    " |-- product_price: double (nullable = true)\n",
    " |-- first_issue_date: timestamp (nullable = true)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
